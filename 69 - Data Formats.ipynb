{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/Continuum_Logo_0702.png)\n",
    "\n",
    "# Scientific Programming using Anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## David Mertz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dmertz@continuum.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016-04-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial, and Python in general, run more smoothly under Python 3.x.\n",
    "\n",
    "Whether you're running on Python 2 or Python 3, please install [Python-Future](http://python-future.org/futurize.html):\n",
    "```bash\n",
    "conda install future\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "from future import standard_library\n",
    "standard_library.install_aliases()\n",
    "from future.builtins import (\n",
    "         bytes, dict, int, list, object, range, str,\n",
    "         ascii, chr, hex, input, next, oct, open,\n",
    "         pow, round, super, filter, map, zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Learning Objectives:](#Learning-Objectives:)\n",
    "* [Not-quite-CSV: Eyeballing the data](#Not-quite-CSV:-Eyeballing-the-data)\n",
    "* [Learning Objectives](#Learning-Objectives)\n",
    "\t* [Preamble](#Preamble)\n",
    "* [Sqlite3](#Sqlite3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completion of this module, learners should be able to:\n",
    "\n",
    "* Read from and write to delimited data files, such as CSV\n",
    "* Learn how to do so robustly\n",
    "* Learn why to not do so if possible\n",
    "* Understand the structure of Excel .xlsx files\n",
    "* Read data from Excel files\n",
    "* Write data to Excel files\n",
    "* Learn what JSON, YAML, and XML are\n",
    "* Learn when and why to use them\n",
    "* Learn how to manipulate and construct each type\n",
    "* Learn the limitations and risks associated with each\n",
    "* Work with formats that mirror the native data structures of Python:\n",
    "* JSON\n",
    "* YAML\n",
    "* Work with XML data using several APIs:\n",
    "* expat\n",
    "* ElementTree\n",
    "* SAX (Simple API for XML)\n",
    "* DOM (Document Object Model\n",
    "* Work with data stored in fast, hierarchical scientific data formats:\n",
    "* HDF5\n",
    "* NetCDF\n",
    "* IDL .sav files\n",
    "* Fortran 77 Unformatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not-quite-CSV: Eyeballing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ---------------------------------- WARNING ----------------------------------------\n",
      "# The data you have obtained from this automated U.S. Geological Survey database\n",
      "# have not received Director's approval and as such are provisional and subject to\n",
      "# revision.  The data are released on the condition that neither the USGS nor the\n",
      "# United States Government may be held liable for any damages resulting from its use.\n",
      "# Additional info: http://help.waterdata.usgs.gov/policies/provisional-data-statement\n",
      "#\n",
      "# File-format description:  http://help.waterdata.usgs.gov/faq/about-tab-delimited-output\n",
      "# Automated-retrieval info: http://help.waterdata.usgs.gov/faq/automated-retrievals\n",
      "#\n",
      "# Contact:   gs-w_support_nwisweb@usgs.gov\n",
      "# retrieved: 2015-06-11 16:58:34 EDT       (sdww01)\n",
      "#\n",
      "# Data for the following 1 site(s) are contained in this file\n",
      "#    USGS 14226500 COWLITZ RIVER AT PACKWOOD, WA\n",
      "# -----------------------------------------------------------------------------------\n",
      "#\n",
      "# Data provided for site 14226500\n",
      "#    DD parameter statistic   Description\n",
      "#    01   00060     00003     Discharge, cubic feet per second (Mean)\n",
      "#\n",
      "# Data-value qualification codes included in this output:\n",
      "#     A  Approved for publication -- Processing and review completed.\n",
      "#     P  Provisional data subject to revision.\n",
      "#     e  Value has been estimated.\n",
      "#\n",
      "agency_cd\tsite_no\tdatetime\t01_00060_00003\t01_00060_00003_cd\n",
      "5s\t15s\t20d\t14n\t10s\n",
      "USGS\t14226500\t1985-01-01\t577\tA\n",
      "USGS\t14226500\t1985-01-02\t568\tA\n",
      "USGS\t14226500\t1985-01-03\t557\tA\n",
      "USGS\t14226500\t1985-01-04\t544\tA\n"
     ]
    }
   ],
   "source": [
    "# More convoluted tab-separated with header lines, etc.\n",
    "# Let's try to figure out how to work with the data\n",
    "cowlitz_file = 'data/cowlitz_river_wa_usgs_flow_data.rdb'\n",
    "cowlitz = open(cowlitz_file).readlines()\n",
    "for line in cowlitz[:32]:\n",
    "    print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject area experts will find the format familiar, I am sure.  The *rdb* format is described at http://help.waterdata.usgs.gov/faq/about-tab-delimited-output as well.  But I am a non-expert in the subject area, so I will just visually examine it, and figure out in a relatively ad hoc way how to read and utilize it.\n",
    "\n",
    "Here are some things I notice:\n",
    "\n",
    "* The file starts with a commented header, with each line beginning with a hash mark (`# `) and space.\n",
    "* The next line after the header is a list of field names.\n",
    " * Some field names start with numbers, and are not valid Python identifiers.\n",
    "* The next line after the field names is the data types of the columns; but I'm not sure exactly what those descriptions mean.\n",
    "* The bulk of the file is tab-separated values.\n",
    "\n",
    "Let's write a small custom function to parse what we see in this data format. Note that I actually *did* a quick search, and it appears the modules `Asciitable` and the package `Astropy` both seem to support this format (other existing libraries might also); but suppose it was something novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_rdb(filename):\n",
    "    import csv\n",
    "    from collections import namedtuple, OrderedDict\n",
    "    fh = open(filename)\n",
    "    # First collect the comments, stopping at the field names\n",
    "    comment_lines = []\n",
    "    for line in fh:\n",
    "        # We've gotten to the header\n",
    "        if not line.startswith('#'):\n",
    "            fields = line.rstrip().split('\\t')\n",
    "            break\n",
    "        comment_lines.append(line[2:])\n",
    "    # Make the individual lines into one string\n",
    "    comment = ''.join(comment_lines)\n",
    "    # Read the next line with the data formats\n",
    "    formats = next(fh).rstrip().split('\\t')\n",
    "    # Make sure field names are valid Python identifiers\n",
    "    field_names = [f if f[0].isalpha() else 'N_'+f for f in fields]\n",
    "    # Define header as ordered mapping of field name to data type\n",
    "    header = OrderedDict(zip(field_names, formats))\n",
    "    row = namedtuple('Row', field_names)\n",
    "    records = []\n",
    "    for values in csv.reader(fh, delimiter='\\t'):\n",
    "        records.append(row(*values))\n",
    "    # Close the file before we leave\n",
    "    fh.close()\n",
    "    return comment, header, records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agency_cd: 5s\n",
      "site_no: 15s\n",
      "datetime: 20d\n",
      "N_01_00060_00003: 14n\n",
      "N_01_00060_00003_cd: 10s\n"
     ]
    }
   ],
   "source": [
    "comment, header, cowlitz_data = read_rdb(cowlitz_file)\n",
    "for field, datatype in header.items():\n",
    "    print(\"%s: %s\" % (field, datatype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- WARNING ----------------------------------------\n",
      "The data you have obtained from this automated U.S. Geological Survey database\n",
      "have not received Director's approval and as such are provisional and subject to\n",
      "revision.  The data are released on the condition that neither the USGS nor the\n",
      "United States Government may be held liable for any damages resulting from its use.\n",
      "Additional info: http://help.waterdata.usgs.gov/policies/provisional-data-statement\n",
      "File-format description:  http://help.waterdata.usgs.gov/faq/about-tab-delimited-output\n",
      "Automated-retrieval info: http://help.waterdata.usgs.gov/faq/automated-retrievals\n",
      "Contact:   gs-w_support_nwisweb@usgs.gov\n",
      "retrieved: 2015-06-11 16:58:34 EDT       (sdww01)\n",
      "Data for the following 1 site(s) are contained in this file\n",
      "   USGS 14226500 COWLITZ RIVER AT PACKWOOD, WA\n",
      "-----------------------------------------------------------------------------------\n",
      "Data provided for site 14226500\n",
      "   DD parameter statistic   Description\n",
      "   01   00060     00003     Discharge, cubic feet per second (Mean)\n",
      "Data-value qualification codes included in this output: \n",
      "    A  Approved for publication -- Processing and review completed.  \n",
      "    P  Provisional data subject to revision.  \n",
      "    e  Value has been estimated.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11118 records, show first five\n",
      "----------\n",
      "Row(agency_cd='USGS', site_no='14226500', datetime='1985-01-01', N_01_00060_00003='577', N_01_00060_00003_cd='A')\n",
      "Row(agency_cd='USGS', site_no='14226500', datetime='1985-01-02', N_01_00060_00003='568', N_01_00060_00003_cd='A')\n",
      "Row(agency_cd='USGS', site_no='14226500', datetime='1985-01-03', N_01_00060_00003='557', N_01_00060_00003_cd='A')\n",
      "Row(agency_cd='USGS', site_no='14226500', datetime='1985-01-04', N_01_00060_00003='544', N_01_00060_00003_cd='A')\n",
      "Row(agency_cd='USGS', site_no='14226500', datetime='1985-01-05', N_01_00060_00003='536', N_01_00060_00003_cd='A')\n",
      "----------\n",
      "Work with a particular record in a straightforward way\n",
      "1987-09-28 14226500 269\n"
     ]
    }
   ],
   "source": [
    "print(\"%d records, show first five\" % len(cowlitz_data))\n",
    "\n",
    "print('----------')\n",
    "for record in cowlitz_data[:5]:\n",
    "    print(record)\n",
    "    \n",
    "print('----------')\n",
    "print(\"Work with a particular record in a straightforward way\")\n",
    "my_row = cowlitz_data[1000]\n",
    "print(my_row.datetime, my_row.site_no, my_row.N_01_00060_00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([r for r in cowlitz_data if r.N_01_00060_00003_cd=='A:e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>datetime</th>\n",
       "      <th>N_01_00060_00003</th>\n",
       "      <th>N_01_00060_00003_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-01</td>\n",
       "      <td>577</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-02</td>\n",
       "      <td>568</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-03</td>\n",
       "      <td>557</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-04</td>\n",
       "      <td>544</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-05</td>\n",
       "      <td>536</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-06</td>\n",
       "      <td>532</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>534</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-08</td>\n",
       "      <td>530</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-09</td>\n",
       "      <td>518</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-10</td>\n",
       "      <td>508</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-11</td>\n",
       "      <td>495</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-12</td>\n",
       "      <td>486</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-13</td>\n",
       "      <td>486</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-14</td>\n",
       "      <td>496</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-15</td>\n",
       "      <td>536</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-16</td>\n",
       "      <td>533</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-17</td>\n",
       "      <td>587</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-18</td>\n",
       "      <td>642</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-19</td>\n",
       "      <td>652</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-20</td>\n",
       "      <td>653</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-21</td>\n",
       "      <td>644</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-22</td>\n",
       "      <td>633</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-23</td>\n",
       "      <td>624</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-24</td>\n",
       "      <td>614</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-25</td>\n",
       "      <td>601</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-26</td>\n",
       "      <td>583</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-27</td>\n",
       "      <td>569</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-28</td>\n",
       "      <td>557</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-29</td>\n",
       "      <td>537</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>1985-01-30</td>\n",
       "      <td>510</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-12</td>\n",
       "      <td>1300</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>1540</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-14</td>\n",
       "      <td>1280</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11091</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-15</td>\n",
       "      <td>1120</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-16</td>\n",
       "      <td>1100</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11093</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-17</td>\n",
       "      <td>1090</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11094</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-18</td>\n",
       "      <td>1100</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11095</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>1130</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11096</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>1160</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11097</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-21</td>\n",
       "      <td>1220</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>1300</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>1270</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-24</td>\n",
       "      <td>1230</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11101</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-25</td>\n",
       "      <td>1150</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11102</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-26</td>\n",
       "      <td>1080</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11103</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>1050</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11104</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>1090</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11105</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-29</td>\n",
       "      <td>1210</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-30</td>\n",
       "      <td>1210</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11107</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>1070</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11108</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>1030</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11109</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>1010</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11110</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-03</td>\n",
       "      <td>962</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11111</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-04</td>\n",
       "      <td>924</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11112</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>884</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11113</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-06</td>\n",
       "      <td>901</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11114</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-07</td>\n",
       "      <td>907</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11115</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-08</td>\n",
       "      <td>936</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11116</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-09</td>\n",
       "      <td>931</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11117</th>\n",
       "      <td>USGS</td>\n",
       "      <td>14226500</td>\n",
       "      <td>2015-06-10</td>\n",
       "      <td>884</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11118 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agency_cd   site_no    datetime N_01_00060_00003 N_01_00060_00003_cd\n",
       "0          USGS  14226500  1985-01-01              577                   A\n",
       "1          USGS  14226500  1985-01-02              568                   A\n",
       "2          USGS  14226500  1985-01-03              557                   A\n",
       "3          USGS  14226500  1985-01-04              544                   A\n",
       "4          USGS  14226500  1985-01-05              536                   A\n",
       "5          USGS  14226500  1985-01-06              532                   A\n",
       "6          USGS  14226500  1985-01-07              534                   A\n",
       "7          USGS  14226500  1985-01-08              530                   A\n",
       "8          USGS  14226500  1985-01-09              518                   A\n",
       "9          USGS  14226500  1985-01-10              508                   A\n",
       "10         USGS  14226500  1985-01-11              495                   A\n",
       "11         USGS  14226500  1985-01-12              486                   A\n",
       "12         USGS  14226500  1985-01-13              486                   A\n",
       "13         USGS  14226500  1985-01-14              496                   A\n",
       "14         USGS  14226500  1985-01-15              536                   A\n",
       "15         USGS  14226500  1985-01-16              533                   A\n",
       "16         USGS  14226500  1985-01-17              587                   A\n",
       "17         USGS  14226500  1985-01-18              642                   A\n",
       "18         USGS  14226500  1985-01-19              652                   A\n",
       "19         USGS  14226500  1985-01-20              653                   A\n",
       "20         USGS  14226500  1985-01-21              644                   A\n",
       "21         USGS  14226500  1985-01-22              633                   A\n",
       "22         USGS  14226500  1985-01-23              624                   A\n",
       "23         USGS  14226500  1985-01-24              614                   A\n",
       "24         USGS  14226500  1985-01-25              601                   A\n",
       "25         USGS  14226500  1985-01-26              583                   A\n",
       "26         USGS  14226500  1985-01-27              569                   A\n",
       "27         USGS  14226500  1985-01-28              557                   A\n",
       "28         USGS  14226500  1985-01-29              537                   A\n",
       "29         USGS  14226500  1985-01-30              510                   A\n",
       "...         ...       ...         ...              ...                 ...\n",
       "11088      USGS  14226500  2015-05-12             1300                   P\n",
       "11089      USGS  14226500  2015-05-13             1540                   P\n",
       "11090      USGS  14226500  2015-05-14             1280                   P\n",
       "11091      USGS  14226500  2015-05-15             1120                   P\n",
       "11092      USGS  14226500  2015-05-16             1100                   P\n",
       "11093      USGS  14226500  2015-05-17             1090                   P\n",
       "11094      USGS  14226500  2015-05-18             1100                   P\n",
       "11095      USGS  14226500  2015-05-19             1130                   P\n",
       "11096      USGS  14226500  2015-05-20             1160                   P\n",
       "11097      USGS  14226500  2015-05-21             1220                   P\n",
       "11098      USGS  14226500  2015-05-22             1300                   P\n",
       "11099      USGS  14226500  2015-05-23             1270                   P\n",
       "11100      USGS  14226500  2015-05-24             1230                   P\n",
       "11101      USGS  14226500  2015-05-25             1150                   P\n",
       "11102      USGS  14226500  2015-05-26             1080                   P\n",
       "11103      USGS  14226500  2015-05-27             1050                   P\n",
       "11104      USGS  14226500  2015-05-28             1090                   P\n",
       "11105      USGS  14226500  2015-05-29             1210                   P\n",
       "11106      USGS  14226500  2015-05-30             1210                   P\n",
       "11107      USGS  14226500  2015-05-31             1070                   P\n",
       "11108      USGS  14226500  2015-06-01             1030                   P\n",
       "11109      USGS  14226500  2015-06-02             1010                   P\n",
       "11110      USGS  14226500  2015-06-03              962                   P\n",
       "11111      USGS  14226500  2015-06-04              924                   P\n",
       "11112      USGS  14226500  2015-06-05              884                   P\n",
       "11113      USGS  14226500  2015-06-06              901                   P\n",
       "11114      USGS  14226500  2015-06-07              907                   P\n",
       "11115      USGS  14226500  2015-06-08              936                   P\n",
       "11116      USGS  14226500  2015-06-09              931                   P\n",
       "11117      USGS  14226500  2015-06-10              884                   P\n",
       "\n",
       "[11118 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(cowlitz_data, columns=header.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Work with SQLite3 single-file databases\n",
    "* Work with RDBMS's using the DBAPI standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11118 rows of data\n",
      "----------\n",
      "Row(agency_cd='USGS', site_no='14226500', datetime='1985-01-01', N_01_00060_00003='577', N_01_00060_00003_cd='A')\n",
      "Row(agency_cd='USGS', site_no='14226500', datetime='1985-01-02', N_01_00060_00003='568', N_01_00060_00003_cd='A')\n",
      "Row(agency_cd='USGS', site_no='14226500', datetime='1985-01-03', N_01_00060_00003='557', N_01_00060_00003_cd='A')\n"
     ]
    }
   ],
   "source": [
    "# Load some data we'll use for later examples\n",
    "import src.rdb as rdb\n",
    "cowlitz_file = 'data/cowlitz_river_wa_usgs_flow_data.rdb'\n",
    "comment, header, cowlitz_data = rdb.read_rdb(cowlitz_file)\n",
    "\n",
    "# Notice the form of this data is a list of namedtuples\n",
    "print(\"%d rows of data\" % len(cowlitz_data), end='\\n----------\\n')\n",
    "for row in cowlitz_data[:3]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8514 rows of data\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-09-16</th>\n",
       "      <td>99.80</td>\n",
       "      <td>101.26</td>\n",
       "      <td>98.89</td>\n",
       "      <td>100.86</td>\n",
       "      <td>66818200</td>\n",
       "      <td>100.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-15</th>\n",
       "      <td>102.81</td>\n",
       "      <td>103.05</td>\n",
       "      <td>101.44</td>\n",
       "      <td>101.63</td>\n",
       "      <td>61216500</td>\n",
       "      <td>101.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-12</th>\n",
       "      <td>101.21</td>\n",
       "      <td>102.19</td>\n",
       "      <td>101.08</td>\n",
       "      <td>101.66</td>\n",
       "      <td>62626100</td>\n",
       "      <td>101.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close    Volume  Adj Close\n",
       "Date                                                           \n",
       "2014-09-16   99.80  101.26   98.89  100.86  66818200     100.86\n",
       "2014-09-15  102.81  103.05  101.44  101.63  61216500     101.63\n",
       "2014-09-12  101.21  102.19  101.08  101.66  62626100     101.66"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some data we'll use for later examples\n",
    "# Note the form of this data is a Pandas DataFrame\n",
    "import pandas as pd\n",
    "aapl = pd.read_csv('data/AAPL.csv', index_col='Date')\n",
    "print(\"%d rows of data\" % len(aapl), end='\\n----------\\n')\n",
    "aapl[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.remove('tmp/test-db')\n",
    "except OSError:\n",
    "    print(\"File already not there\")\n",
    "#!rm tmp/test-db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect(\"tmp/test-db\")\n",
    "db.execute(\"create table stocks \"\n",
    "           \"(symbol text, shares integer, price real, \"\n",
    "           \" primary key (symbol))\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.execute(\"insert into stocks values (?, ?, ?)\", ('IBM', 50, 91.10))\n",
    "db.execute(\"insert into stocks values (?, ?, ?)\", ('AAPL', 100, 123.45))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IBM', 50, 91.1)\n",
      "('AAPL', 100, 123.45)\n"
     ]
    }
   ],
   "source": [
    "for row in db.execute(\"select * from stocks\"):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks = [('GOOG', 75, 380.13), ('AA', 100, 14.20), ('AIG', 124, 0.99)]\n",
    "db.executemany(\"insert into stocks values (?, ?, ?)\", stocks)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IBM', 50, 91.1),\n",
       " ('AAPL', 100, 123.45),\n",
       " ('GOOG', 75, 380.13),\n",
       " ('AA', 100, 14.2),\n",
       " ('AIG', 124, 0.99)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.execute(\"select * from stocks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AAPL', 123.45), ('AA', 14.2), ('AIG', 0.99)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.execute(\"select symbol, price from stocks where shares >= 100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "raises": "IntegrityError"
   },
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: stocks.symbol",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7ead0b9872a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"insert into stocks values (?, ?, ?)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'IBM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m124.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: UNIQUE constraint failed: stocks.symbol"
     ]
    }
   ],
   "source": [
    "db.execute(\"insert into stocks values (?, ?, ?)\", ('IBM', 100, 124.5))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: dir: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!dir tmp\\test-db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.execute(\"CREATE TABLE cowlitz \"\n",
    "           \"(agency_cd TEXT, site_no INTEGER, date DATE, \"\n",
    "           \" discharge REAL, status TEXT, PRIMARY KEY (date))\")\n",
    "for row in cowlitz_data:\n",
    "    db.execute(\"INSERT INTO cowlitz VALUES (?, ?, ?, ?, ?)\", row)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(908,)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = db.execute('SELECT COUNT(*) FROM cowlitz WHERE status=\"A:e\"')\n",
    "list(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('USGS', 14226500, '1988-01-01', 381.0, 'A')\n",
      "('USGS', 14226500, '1988-01-02', 363.0, 'A')\n",
      "('USGS', 14226500, '1988-01-03', 347.0, 'A')\n",
      "('USGS', 14226500, '1988-01-04', 355.0, 'A')\n",
      "('USGS', 14226500, '1988-01-05', 355.0, 'A')\n",
      "('USGS', 14226500, '1988-01-06', 351.0, 'A')\n",
      "('USGS', 14226500, '1988-01-07', 347.0, 'A')\n",
      "('USGS', 14226500, '1988-01-08', 343.0, 'A')\n",
      "('USGS', 14226500, '1988-01-09', 349.0, 'A')\n"
     ]
    }
   ],
   "source": [
    "for d in db.execute('SELECT * FROM cowlitz WHERE '\n",
    "                    'date >= \"1988-01-01\" AND date < \"1988-01-10\"'):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 dmertz  staff  610304 Apr 24 22:10 tmp/test-db\n",
      "-rwxr-xr-x@ 1 dmertz  staff  354101 Apr 16 00:38 \u001b[1m\u001b[31mdata/cowlitz_river_wa_usgs_flow_data.rdb\u001b[m\u001b[m*\n"
     ]
    }
   ],
   "source": [
    "%ls -l tmp/test-db\n",
    "%ls -l $cowlitz_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj_Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-09-16</th>\n",
       "      <td>99.80</td>\n",
       "      <td>101.26</td>\n",
       "      <td>98.89</td>\n",
       "      <td>100.86</td>\n",
       "      <td>66818200</td>\n",
       "      <td>100.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-15</th>\n",
       "      <td>102.81</td>\n",
       "      <td>103.05</td>\n",
       "      <td>101.44</td>\n",
       "      <td>101.63</td>\n",
       "      <td>61216500</td>\n",
       "      <td>101.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-12</th>\n",
       "      <td>101.21</td>\n",
       "      <td>102.19</td>\n",
       "      <td>101.08</td>\n",
       "      <td>101.66</td>\n",
       "      <td>62626100</td>\n",
       "      <td>101.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close    Volume  Adj_Close\n",
       "Date                                                           \n",
       "2014-09-16   99.80  101.26   98.89  100.86  66818200     100.86\n",
       "2014-09-15  102.81  103.05  101.44  101.63  61216500     101.63\n",
       "2014-09-12  101.21  102.19  101.08  101.66  62626100     101.66"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need Pandas column names to be valid SQL column names\n",
    "aapl['Adj_Close'] = aapl['Adj Close']\n",
    "del aapl['Adj Close']\n",
    "aapl[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl.to_sql('AAPL', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2014-09-16', 99.8, 101.26, 98.89, 100.86, 66818200, 100.86)\n",
      "('2014-09-15', 102.81, 103.05, 101.44, 101.63, 61216500, 101.63)\n",
      "('2014-09-12', 101.21, 102.19, 101.08, 101.66, 62626100, 101.66)\n",
      "('2014-09-11', 100.41, 101.44, 99.62, 101.43, 62353100, 101.43)\n",
      "('2014-09-10', 98.01, 101.11, 97.76, 101.0, 100741900, 101.0)\n",
      "('2014-09-09', 99.08, 103.08, 96.14, 97.99, 189560600, 97.99)\n",
      "('2014-09-08', 99.3, 99.31, 98.05, 98.36, 46277800, 98.36)\n",
      "('2014-09-05', 98.8, 99.39, 98.31, 98.97, 58353200, 98.97)\n",
      "('2014-09-04', 98.85, 100.09, 97.79, 98.12, 85594800, 98.12)\n",
      "('2014-09-03', 103.1, 103.2, 98.58, 98.94, 125233100, 98.94)\n"
     ]
    }
   ],
   "source": [
    "for row in db.execute(\"SELECT * FROM AAPL LIMIT 10\"):\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "continuum": {
   "depends": [
    "ip_containers",
    "ip_standard",
    "ip_files"
   ],
   "requires": [
    "data/AAPL.csv",
    "data/AAPL01.csv",
    "data/cowlitz_river_wa_usgs_flow_data.rdb"
   ],
   "tag": "data_csv"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
