{"nbformat_minor": 0, "worksheets": [{"cells": [{"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 2, "input": ["import pymbolic.primitives as p\n", "\n", "u = p.Variable(\"u\")"], "cell_type": "code", "outputs": []}, {"cell_type": "markdown", "source": ["We'll write code that evaluates $\\triangle u$ using finite differences.\n", "\n", "To that end, we define a new expression 'thing': An operator for the Laplacian."], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 3, "input": ["class Laplacian(p.Expression):\n", "    def __init__(self, child):\n", "        self.child = child\n", "        \n", "    def __getinitargs__(self):\n", "        return (self.child,)\n", "    \n", "    mapper_method = \"map_laplacian\"\n", "        \n", "pde = Laplacian(u)+u**2-1\n", "pde"], "cell_type": "code", "outputs": [{"output_type": "pyout", "prompt_number": 3, "text": ["Sum((Laplacian(Variable('u')), Power(Variable('u'), 2), -1))"], "metadata": {}}]}, {"cell_type": "markdown", "source": ["Now we'll write code to turn Laplacians into their discrete finite difference forms, using `i` and `j` as formal indices, using\n", "\n", "$$f''(x) \\approx \\frac{f(x+h) - 2 f(x) + f(x-h)}{h^{2}}$$\n", "\n", "Pay close attention to indexing!"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 4, "input": ["from pymbolic.mapper import IdentityMapper\n", "\n", "i = p.Variable(\"i\")\n", "j = p.Variable(\"j\")\n", "\n", "ii = i+1\n", "jj = j+1"], "cell_type": "code", "outputs": []}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 5, "input": ["class FDMapper(IdentityMapper):\n", "    def map_variable(self, expr):\n", "        return expr[i, j]\n", "    \n", "    def map_laplacian(self, expr):\n", "        var = expr.child\n", "        return (-4*var[ii,jj] + var[ii+1,jj] + var[ii-1,jj]\n", "                + var[ii,jj+1] + var[ii,jj-1])"], "cell_type": "code", "outputs": []}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 6, "input": ["fd_mapper = FDMapper()\n", "print fd_mapper(pde)"], "cell_type": "code", "outputs": [{"output_type": "stream", "text": ["u[(i, j)]**2 + -1 + (-4)*u[(i + 1, j + 1)] + u[(i + 1 + 1, j + 1)] + u[(i + 1 + -1, j + 1)] + u[(i + 1, j + 1 + 1)] + u[(i + 1, j + 1 + -1)]\n"], "stream": "stdout"}]}, {"cell_type": "markdown", "source": ["----\n", "\n", "Now let's generate some code for this, using `loopy`:"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 7, "input": ["import loopy as lp\n", "\n", "result = p.Variable(\"result\")"], "cell_type": "code", "outputs": [{"output_type": "stream", "text": ["/usr/lib/python2.7/pkgutil.py:186: ImportWarning: Not importing directory '/usr/lib/python2.7/dist-packages/enthought': missing __init__.py\n", "  file, filename, etc = imp.find_module(subname, path)\n"], "stream": "stderr"}]}, {"cell_type": "markdown", "source": ["Observe the two parts of the `loopy` kernel description:\n", "\n", "* Polyhedral loop domain\n", "* Instructions"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 8, "input": ["knl = lp.make_kernel(\n", "    \"{[i,j]: 0<=i,j<n}\",\n", "    [lp.ExpressionInstruction(result[i,j], fd_mapper(pde))],\n", "    )"], "cell_type": "code", "outputs": []}, {"cell_type": "markdown", "source": ["Kernels can always be inspected--simply use `print`:"], "metadata": {}}, {"language": "python", "collapsed": true, "metadata": {}, "prompt_number": 9, "input": ["print knl"], "cell_type": "code", "outputs": [{"output_type": "stream", "text": ["---------------------------------------------------------------------------\n", "KERNEL: loopy_kernel\n", "---------------------------------------------------------------------------\n", "ARGUMENTS:\n", "n: ValueArg, type: <runtime>\n", "result: GlobalArg, type: <runtime>, shape: (n, n), dim_tags: (stride:n, stride:1)\n", "u: GlobalArg, type: <runtime>, shape: (2 + n, 2 + n), dim_tags: (stride:2 + n, stride:1)\n", "---------------------------------------------------------------------------\n", "DOMAINS:\n", "[n] -> { [i, j] : i >= 0 and j >= 0 and i <= -1 + n and j <= -1 + n }\n", "---------------------------------------------------------------------------\n", "INAME IMPLEMENTATION TAGS:\n", "i: None\n", "j: None\n", "---------------------------------------------------------------------------\n", "INSTRUCTIONS:\n", "[i,j]                                result[(i, j)] <- u[(i, j)]**2 + -1 + (-4)*u[(i + 1, j + 1)] + u[(i + 1 + 1, j + 1)] + u[(i + 1 + -1, j + 1)] + u[(i + 1, j + 1 + 1)] + u[(i + 1, j + 1 + -1)]   # insn\n", "---------------------------------------------------------------------------\n"], "stream": "stdout"}]}, {"cell_type": "markdown", "source": ["----\n", "\n", "Let's move towards running this code. To do so, we need `pyopencl`:"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 10, "input": ["import numpy as np\n", "import pyopencl as cl\n", "import pyopencl.array\n", "import pyopencl.clrandom\n", "\n", "ctx = cl.create_some_context()\n", "queue = cl.CommandQueue(ctx)"], "cell_type": "code", "outputs": []}, {"cell_type": "markdown", "source": ["And some data to work with:"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 11, "input": ["n = 1000\n", "u = cl.clrandom.rand(queue, (n+2,n+2), dtype=np.float32)"], "cell_type": "code", "outputs": [{"output_type": "stream", "text": ["/home/andreas/src/pyopencl/pyopencl/__init__.py:61: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n", "  \"to see more.\", CompilerWarning)\n"], "stream": "stderr"}]}, {"cell_type": "markdown", "source": ["Now run the code, and tell loopy to print what it generates:"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 12, "input": ["knl = lp.set_options(knl, write_cl=True)\n", "\n", "evt, (result,) = knl(queue, u=u, n=n)"], "cell_type": "code", "outputs": [{"output_type": "stream", "text": ["\n", "#define lid(N) ((int) get_local_id(N))\n", "#define gid(N) ((int) get_group_id(N))\n", "\n", "__kernel void __attribute__ ((reqd_work_group_size(1, 1, 1))) loopy_kernel(int const n, __global float *restrict result, __global float const *restrict u)\n", "{\n", "\n", "  for (int i = 0; i <= (-1 + n); ++i)\n", "    for (int j = 0; j <= (-1 + n); ++j)\n", "      result[n * i + j] = u[(2 + n) * i + j] * u[(2 + n) * i + j] + -1.0f + -4.0f * u[(2 + n) * (i + 1) + j + 1] + u[(2 + n) * (i + 1 + 1) + j + 1] + u[(2 + n) * (i + 1 + -1) + j + 1] + u[(2 + n) * (i + 1) + j + 1 + 1] + u[(2 + n) * (i + 1) + j + 1 + -1];\n", "}\n"], "stream": "stdout"}, {"output_type": "stream", "text": ["/home/andreas/src/loopy/loopy/compiled.py:685: LoopyWarning: kernel scheduling was ambiguous--more than one schedule found, ignoring\n", "  kernel = get_one_scheduled_kernel(kernel)\n"], "stream": "stderr"}]}, {"cell_type": "markdown", "source": ["That's obviously not very parallel. Introduce parallelism:"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 16, "input": ["tknl = knl\n", "tknl = lp.tag_inames(tknl, {\"i\": \"g.0\", \"j\": \"g.1\"})\n", "evt, (result,) = tknl(queue, u=u)"], "cell_type": "code", "outputs": [{"output_type": "stream", "text": ["\n", "#define lid(N) ((int) get_local_id(N))\n", "#define gid(N) ((int) get_group_id(N))\n", "\n", "__kernel void __attribute__ ((reqd_work_group_size(1, 1, 1))) loopy_kernel(int const n, __global float *restrict result, __global float const *restrict u)\n", "{\n", "\n", "  result[n * gid(0) + gid(1)] = u[(2 + n) * gid(0) + gid(1)] * u[(2 + n) * gid(0) + gid(1)] + -1.0f + -4.0f * u[(2 + n) * (gid(0) + 1) + gid(1) + 1] + u[(2 + n) * (gid(0) + 1 + 1) + gid(1) + 1] + u[(2 + n) * (gid(0) + 1 + -1) + gid(1) + 1] + u[(2 + n) * (gid(0) + 1) + gid(1) + 1 + 1] + u[(2 + n) * (gid(0) + 1) + gid(1) + 1 + -1];\n", "}\n"], "stream": "stdout"}]}, {"cell_type": "markdown", "source": ["But OpenCL/CUDA require blocking to be efficient!"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 17, "input": ["sknl = knl\n", "sknl = lp.split_iname(sknl,\n", "        \"i\", 16, outer_tag=\"g.1\", inner_tag=\"l.1\")\n", "sknl = lp.split_iname(sknl,\n", "        \"j\", 16, outer_tag=\"g.0\", inner_tag=\"l.0\")\n", "evt, (result,) = sknl(queue, u=u)"], "cell_type": "code", "outputs": [{"output_type": "stream", "text": ["\n", "#define lid(N) ((int) get_local_id(N))\n", "#define gid(N) ((int) get_group_id(N))\n", "\n", "__kernel void __attribute__ ((reqd_work_group_size(16, 16, 1))) loopy_kernel(int const n, __global float *restrict result, __global float const *restrict u)\n", "{\n", "\n", "  if (\n", "      (-1 + -16 * gid(0) + -1 * lid(0) + n) >= 0\n", "      && (-1 + -16 * gid(1) + -1 * lid(1) + n) >= 0\n", "    )\n", "    result[n * (lid(1) + gid(1) * 16) + lid(0) + gid(0) * 16] = u[(2 + n) * (lid(1) + gid(1) * 16) + lid(0) + gid(0) * 16] * u[(2 + n) * (lid(1) + gid(1) * 16) + lid(0) + gid(0) * 16] + -1.0f + -4.0f * u[(2 + n) * (1 + lid(1) + gid(1) * 16) + 1 + lid(0) + gid(0) * 16] + u[(2 + n) * (1 + 1 + lid(1) + gid(1) * 16) + 1 + lid(0) + gid(0) * 16] + u[(2 + n) * (1 + -1 + lid(1) + gid(1) * 16) + 1 + lid(0) + gid(0) * 16] + u[(2 + n) * (1 + lid(1) + gid(1) * 16) + 1 + 1 + lid(0) + gid(0) * 16] + u[(2 + n) * (1 + lid(1) + gid(1) * 16) + 1 + -1 + lid(0) + gid(0) * 16];\n", "}\n"], "stream": "stdout"}]}, {"cell_type": "markdown", "source": ["How about some data reuse?"], "metadata": {}}, {"language": "python", "collapsed": false, "metadata": {}, "prompt_number": 14, "input": ["sknl = knl\n", "sknl = lp.split_iname(sknl,\n", "        \"i\", 16, outer_tag=\"g.1\", inner_tag=\"l.1\")\n", "sknl = lp.split_iname(sknl,\n", "        \"j\", 16, outer_tag=\"g.0\", inner_tag=\"l.0\")\n", "sknl = lp.add_prefetch(sknl, \"u\",\n", "    [\"i_inner\", \"j_inner\"],\n", "    fetch_bounding_box=True)\n", "evt, (result,) = sknl(queue, u=u, n=n)"], "cell_type": "code", "outputs": [{"output_type": "stream", "text": ["\n", "#define lid(N) ((int) get_local_id(N))\n", "#define gid(N) ((int) get_group_id(N))\n", "\n", "__kernel void __attribute__ ((reqd_work_group_size(16, 16, 1))) loopy_kernel(int const n, __global float *restrict result, __global float const *restrict u)\n", "{\n", "  __local float u_fetch_0[18 * 18];\n", "\n", "  for (int u_dim_0_outer = 0; u_dim_0_outer <= 1; ++u_dim_0_outer)\n", "    if (\n", "        (1 + -16 * u_dim_0_outer + -1 * lid(1) + -16 * gid(1) + n) >= 0\n", "        && (17 + -16 * u_dim_0_outer + -1 * lid(1)) >= 0\n", "      )\n", "      for (int u_dim_1_outer = 0; u_dim_1_outer <= 1; ++u_dim_1_outer)\n", "        if (\n", "            (1 + -16 * u_dim_1_outer + -1 * lid(0) + -16 * gid(0) + n) >= 0\n", "            && (17 + -16 * u_dim_1_outer + -1 * lid(0)) >= 0\n", "          )\n", "          u_fetch_0[18 * (lid(1) + u_dim_0_outer * 16) + lid(0) + u_dim_1_outer * 16] = u[(2 + n) * (16 * gid(1) + lid(1) + u_dim_0_outer * 16) + 16 * gid(0) + lid(0) + u_dim_1_outer * 16];\n", "  barrier(CLK_LOCAL_MEM_FENCE) /* for u_fetch_0 (insn depends on u_fetch) */;\n", "  if (\n", "      (-1 + -16 * gid(0) + -1 * lid(0) + n) >= 0\n", "      && (-1 + -16 * gid(1) + -1 * lid(1) + n) >= 0\n", "    )\n", "    result[n * (lid(1) + gid(1) * 16) + lid(0) + gid(0) * 16] = u_fetch_0[18 * lid(1) + lid(0)] * u_fetch_0[18 * lid(1) + lid(0)] + -1.0f + -4.0f * u_fetch_0[18 * (1 + lid(1)) + 1 + lid(0)] + u_fetch_0[18 * (2 + lid(1)) + 1 + lid(0)] + u_fetch_0[18 * lid(1) + 1 + lid(0)] + u_fetch_0[18 * (1 + lid(1)) + 2 + lid(0)] + u_fetch_0[18 * (1 + lid(1)) + lid(0)];\n", "}\n"], "stream": "stdout"}]}], "metadata": {}}], "nbformat": 3, "metadata": {"name": "", "signature": "sha256:996e1e45906821d74265b3be0e30068b14eae808a59a97487912af13d81ef11d"}}