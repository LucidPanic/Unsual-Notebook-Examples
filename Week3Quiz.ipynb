{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quick Quiz\n",
    "\n",
    "1. Each answer is only one line long: \n",
    "    * Answer like this:\n",
    "        * Q1  $\\ldots$\n",
    "        * Q2 ...\n",
    "        * ....\n",
    "1. You have 40 minutes.\n",
    "1. The quiz is obligatory.\n",
    "1. You pass if you have at least 5 of the 10 questions correct.\n",
    "1. All code must be syntactically correct Python code.\n",
    "1. You may use IPython notebook on your laptop, but nothing else.\n",
    "1. You write your answers on the provided exam sheet. This exam sheet will be scored by a peer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extracting information from the web\n",
    "\n",
    "In the questions below, show that yoir code works well by downloading <http://www.nltk.org/book/ch05.html>, and applying the questions to that page.\n",
    "\n",
    "* **Q1** Give the complete Python code needed to download a webpage whose address is stored in variable `url` and read it in as a string.\n",
    "* **Q2** Extend your code to parse it as a beautifulsoup object.\n",
    "* **Q3** Define the variable `headers` which contains all h1, h2, h3 headers from the downloaded webpage.\n",
    "* **Q4** Define the variable `anchor_text` as a list which contains all anchor text on the webpage (i.e., highlighted text which can be clicked to go to another page). Use list comprehension. Make sure you do NOT include empty strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### POS tags\n",
    "The definitions you give in the questions below should work correctly on any input of the same form, not just on the provided example.\n",
    "\n",
    "* **Q5** Consider this code\n",
    "```\n",
    ">>> text = nltk.word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    ">>> nltk.pos_tag(text)\n",
    "[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'),\n",
    "('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]\n",
    "```\n",
    "Define the list `nouns` which contains all nouns (just the words) from the above sentence. Of course you use list comprehension ;-)\n",
    "* **Q6** The same as the last question but now you want all verbs.\n",
    "* **Q7** Consider this code:\n",
    "```\n",
    ">>> sent = '''\n",
    "... The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n",
    "... other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n",
    "... Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n",
    "... said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n",
    "... accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n",
    "... interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
    "... '''\n",
    "```\n",
    "The variable `sent` contains this long string of words together with their POS tag. \n",
    "Define the list `adj` which contains all adjectives in `sent` (these are the words tagged with a POS tag starting with `JJ`). Thus we adhectives the words _without the POS tag_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probabilities\n",
    "* **Q8** `log2()` denotes logarithm with base 2. What is the result of the following four statements?\n",
    "```\n",
    "print log2((1/8)/ (1/8))\n",
    "print log2(1/16)\n",
    "print log2((1/8)/ (1/2))\n",
    "print log2((1/2)/ (1/16))\n",
    "```\n",
    "* **Q9** Let `HP` be a dict containing all words in the complete Harry Potter works as keys and how often they occur in those books as values. Let `HPc` be the total number of words in all Harry Potter books. Define the dict `HPprob` with the same keys as `HP`, but as values for each word `w`, the probability that a random word taken from the Harry Potter books equals `w`.\n",
    "Use _Maximum Likelihood Estimation_ (MLE) to estimate the probabilities. Bonus if you define `HPc` yourself. \n",
    "* **Q10** Let `HP` be the dict from the previous question. Let `stopwords` be a list of stopwords. Calculate the percentage stopwords in the Harry Potter books (alternatively: the probability that a random word in Harry Potter is a stopword). In your code you may also use the variables `HPc` and `HPprob` with the meaning as in the previous question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# code challenge\n",
    "\n",
    "Write a function that determines if any given string has all unique characters (i.e. no character in the string is duplicated). \n",
    "\n",
    "* If the string has all unique characters, print \"all unique\". If the string does not have all unique characters, print \"duplicates found.\"\n",
    "\n",
    "* If the string has all unique characters, return True, else return False. Just use one line. Use no additional memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
